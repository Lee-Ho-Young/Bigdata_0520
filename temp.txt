#=========================== Filebeat inputs =============================

filebeat.inputs:
- type: log
  enabled: true
  paths:
    - F:\onTuneLog\ontune_event_*.dat
  fields :
   app_group : ontune
   app_id : event

   
  ### Multiline options

  # Multiline can be used for log messages spanning multiple lines. This is common
  # for Java Stack Traces or C-Line Continuation

  # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [
  #multiline.pattern: ^\[

  # Defines if the pattern set under pattern should be negated or not. Default is false.
  #multiline.negate: false

  # Match can be set to "after" or "before". It is used to define if lines should be append to a pattern
  # that was (not) matched before or after or as long as a pattern is not matched based on negate.
  # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash
  #multiline.match: after

#================================ Outputs =====================================

# Configure what output to use when sending the data collected by the beat.

#----------------------------- Logstash output --------------------------------
output.logstash:
  # The Logstash hosts
  hosts: ["150.2.237.16:8791"]  # Optional SSL. By default is off.
  # List of root certificates for HTTPS server verifications
  #ssl.certificate_authorities: ["/etc/pki/root/ca.pem"]

  # Certificate for SSL client authentication
  #ssl.certificate: "/etc/pki/client/cert.pem"

  # Client Certificate Key
  #ssl.key: "/etc/pki/client/cert.key"
#================================ Logging =====================================

# Sets log level. The default log level is info.
# Available log levels are: error, warning, info, debug
#logging.level: debug

# At debug level, you can selectively enable logging only for some components.
# To enable all selectors use ["*"]. Examples of other selectors are "beat",
# "publish", "service".
#logging.selectors: ["*"]

​
















input 
 { beats
   {
    port=>"8790"
    codec=>plain  
   }
 } 

  output 
 { 
  if [fields][app_group] == "anycatcher"
   {
     if [fields][app_id] == "os" 
     {
      kafka
      {
        bootstrap_servers=>'150.2.237.16:6667'
        topic_id=>'1-anycatcher1-os'
        codec=>json { charset => "UTF-8" } 
      }
     }
   }
  }


$ ./bin/logstash agent –f config/logstash.config –auto-reload


pipelines.yml
- pipeline.id: sysmaster
   path.config: "/usr/share/logstash/connectconf/tibero.conf"
   pipeline.workers : 6 
- pipeline.id: anycatcher
   path.config: "/usr/share/logstash/connectconf/anycatcher.conf"
   pipeline.workers : 6
- pipeline.id: ontune
   path.config: "/usr/share/logstash/connectconf/ontune.conf"
   pipeline.workers : 4




$ nohup ./bin/logstash --path.settings /etc/logstash 1> /dev/null 2>&1 &



echo "`uname -n`||`date +'%y%m%d%H%M%S'`||CPU||`sar 1 1 | grep Average | awk '{print $3"||"$4"||"$5"||"$6"||"$7"||"$8}'`||MEM||`free -m | grep Mem | awk '{print $2"||"$3"||"$4}'`||SWAP||`free -m | grep Swap | awk '{print $2"||"$3"||"$4}'`"


